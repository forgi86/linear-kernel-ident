import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
import sys
import control
import examples.RLC.symbolic_RLC
import kernelid.kernel

sys.path.append(os.path.join("..", '..'))


if __name__ == '__main__':

    # In[Set seed for reproducibility]
    np.random.seed(0)
    #torch.manual_seed(0)

    # In[Overall parameters]
    add_noise = True
    m = 200  # number of FIR coefficients
    d = 0  # system delay

    # In[Load dataset]

    # RLC series circuit dataset generated by the script RLC_generate_id.py
    COL_T = ['time']
    COL_X = ['V_C', 'I_L']
    COL_U = ['V_IN']
    COL_Y = ['V_C']
    df_X = pd.read_csv(os.path.join("data", "RLC_data_id.csv"))
    time_data = np.array(df_X[COL_T], dtype=np.float32)
    x = np.array(df_X[COL_X], dtype=np.float32)
    u = np.array(df_X[COL_U], dtype=np.float32)
    Td = time_data[1, 0] - time_data[0, 0]

    # In[Add measurement noise]
    std_noise_V = add_noise * 1.0
    std_noise_I = add_noise * 1.0
    std_noise = np.array([std_noise_V, std_noise_I])
    x_noise = np.copy(x) + np.random.randn(*x.shape)*std_noise
    x_noise = x_noise.astype(np.float32)
    y_noise = x_noise[:, [0]]
    y_nonoise = x[:, [0]]

    # In[Compute SNR]
    P_x = np.mean(x ** 2, axis=0)
    P_n = std_noise**2
    SNR = P_x/(P_n+1e-10)
    SNR_db = 10*np.log10(SNR)

    # In[Set-up FIR regression]
    PHI, Y = kernelid.kernel.fir_regressor(u, m, d=d, y=y_noise)
    _, Y_nonoise = kernelid.kernel.fir_regressor(u, m, d=d, y=y_nonoise)
    N = Y.shape[0]
    sigma_e = std_noise_V
    T = np.arange(m)

    # In[Maximum Likelihood FIR estimate]

    ghat_ML = np.linalg.lstsq(PHI, Y, rcond=None)
    ghat_ML = ghat_ML[0]
    ghat_ML = ghat_ML.ravel()
    Y_hat = PHI @ ghat_ML

    # Covariance of the ML estimate
    P_ML = sigma_e**2 * np.linalg.inv(PHI.T @ PHI)
    sigma_ML= np.sqrt(np.diag(P_ML))
    ghat_ML_max = ghat_ML + 3*sigma_ML
    ghat_ML_min = ghat_ML - 3*sigma_ML

    # In[Regularized Bayesian FIR estimate]

    # DC Kernel parameters
    c = 5.6
    alpha = 0.033
    beta = 0.1
    kernel_fun = lambda i, j: kernelid.kernel.DC_kernel(i, j, c, alpha, beta)
    P_prior = kernelid.kernel.kernel_covariance(kernel_fun, m)

    ghat_reg = np.linalg.inv(P_prior @ PHI.T @ PHI + sigma_e ** 2 * np.eye(m)) @ P_prior @ PHI.T @ Y
    ghat_reg = ghat_reg.ravel()

    # Covariance of the Bayesian estimate
    P_post = P_prior - P_prior @ PHI.T @ np.linalg.inv(PHI @ P_prior @ PHI.T + sigma_e ** 2 * np.eye(N)) @ PHI @ P_prior # slow, try a faster implementation...
    sigma_reg = np.sqrt(np.diag(P_post))
    ghat_reg_max = ghat_reg + 3*sigma_reg
    ghat_reg_min = ghat_reg - 3*sigma_reg

    # In[Evaluate the true inpulse response of the RLC]
    ss_model = control.ss(examples.RLC.symbolic_RLC.A_nominal, examples.RLC.symbolic_RLC.B_nominal, np.array([1, 0]), np.array(0))
    ss_model_dt = control.c2d(ss_model, Td)

    T_imp = np.arange(m+1) * Td
    T_imp, g_true = control.impulse_response(ss_model_dt, T_imp)
    T_imp = np.arange(T_imp.size)


    # In[Plot estimated models]

    fig, ax = plt.subplots(1, 2)
    ax[0].plot(T, ghat_ML, 'r')
    ax[0].fill_between(T, ghat_ML_min, ghat_ML_max, where=ghat_ML_max >= ghat_ML_min, facecolor='red', interpolate=True, alpha=0.2)
    ax[0].plot(T_imp, g_true, 'k')
    ax[1].plot(T, ghat_reg, 'g')
    ax[1].fill_between(T, ghat_reg_min, ghat_reg_max, where=ghat_reg_max >= ghat_reg_min, facecolor='green', alpha=0.2)
    ax[1].plot(T_imp, g_true, 'k')

    # In[Prior model plot]
    sigma_prio = np.sqrt(np.diag(P_prior))
    ghat_prio_max = 0 + 3*sigma_prio
    ghat_prio_min = 0 - 3*sigma_prio
    fig, ax = plt.subplots()
    ax.fill_between(T, ghat_prio_min, ghat_prio_max, where=ghat_prio_max>=ghat_prio_min, facecolor='blue', alpha=0.2)
    # Random realizations from the prior
    for idx_mc in range(100):
        ghat_rand = np.random.multivariate_normal(np.zeros(m), P_prior)
        plt.plot(T, ghat_rand, 'b')


    # In[Preditions plot]
    plt.figure()
    plt.plot(Y_nonoise, 'k')  # true outputs
    plt.plot(Y_hat, 'r')  # non-regularized estimate

    # In[Marginal likelihood for different values of the measurement noise level]

    #SIGMA_VEC = np.arange(0.1, 10, 0.1)
    #MARG_VEC = []
    #for idx, sigma_vec in enumerate(SIGMA_VEC):
    #    K_vec = PHI @ P_prior @ PHI.T + sigma_vec ** 2 * np.eye(N)
    #    marglik = kernelid.kernel.get_marglik(Y, K_vec)
    #    MARG_VEC.append(marglik.item())

    # In[Marginal likelihood plot]
    #plt.figure()
    #plt.plot(SIGMA_VEC, MARG_VEC)